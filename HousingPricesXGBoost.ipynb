{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides predictions for housing prices in San Francisco, using XGBoost. The initial data analysis and feature engineering is provided in the HousingPrices notebook.\n",
    "\n",
    "First we load the data and engineer the features as discussed in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_key = 'housing_data_raw.csv'\n",
    "housing = pd.read_csv(data_key)\n",
    "base_housing = housing\n",
    "df = pd.DataFrame(housing)\n",
    "\n",
    "def drop_outliers(data):\n",
    "    data = data.drop([1618])\n",
    "    data = data.drop([3405])\n",
    "    data = data.drop([10652])\n",
    "    data = data.drop([954])\n",
    "    data = data.drop([11136])\n",
    "    data = data.drop([5103])\n",
    "    data = data.drop([916])\n",
    "    data = data.drop([10967])\n",
    "    data = data.drop([7383])\n",
    "    data = data.drop([1465])\n",
    "    data = data.drop([8967])\n",
    "    data = data.drop([8300])\n",
    "    data = data.drop([4997])  \n",
    "    return data\n",
    "\n",
    "housing = drop_outliers(housing)\n",
    "housing['finishedsqft'].sort_values()\n",
    "housing['lastsolddateint'] = pd.to_datetime(housing['lastsolddate'], format='%m/%d/%Y').astype('int')\n",
    "housing['lastsolddateint'] = housing['lastsolddateint']/1000000000\n",
    "housing = housing[housing['lastsolddateint'].notnull()]\n",
    "clean_data = housing.copy()\n",
    "def drop_geog(data, keep = []):\n",
    "    remove_list = ['info','address','z_address','longitude','latitude','neighborhood','lastsolddate','zipcode','zpid','usecode', 'zestimate','zindexvalue']\n",
    "    for k in keep:\n",
    "        remove_list.remove(k)\n",
    "    data = data.drop(remove_list, axis=1)\n",
    "    data = data.drop(data.columns[data.columns.str.contains('unnamed',case = False)],axis = 1)\n",
    "    return data\n",
    "\n",
    "housing = drop_geog(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(data):\n",
    "    y = data['lastsoldprice']\n",
    "    X = data.drop('lastsoldprice', axis=1)\n",
    "    # Return (X_train, X_test, y_train, y_test)\n",
    "    return train_test_split(X, y, test_size=0.3, random_state=30)\n",
    "\n",
    "housing_split = split_data(housing)\n",
    "#regression_model = lin_reg(*housing_split)\n",
    "housing_cleaned = drop_geog(clean_data.copy(), ['neighborhood'])\n",
    "one_hot = pd.get_dummies(housing_cleaned['neighborhood'])\n",
    "housing_cleaned = housing_cleaned.drop('neighborhood',axis = 1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "(X_train, X_test, y_train, y_test) = split_data(housing_cleaned)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train[X_train.columns] = scaler.transform(X_train[X_train.columns])\n",
    "X_train = X_train.join(one_hot)\n",
    "X_test[X_test.columns] = scaler.transform(X_test[X_test.columns])\n",
    "X_test = X_test.join(one_hot)\n",
    "\n",
    "(X_val, X_test, y_val, y_test) = train_test_split(X_test, y_test, test_size=0.5, random_state=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we make some initial predictions on this data with the XGBoost library. Using GridSearchCV allows us to build the models using a number of possible hyperparameters, choosing the best set. This takes quite a while, so the best params (discovered by training the models) are left commented in case the reader prefers to use only those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done 215 tasks      | elapsed:   49.7s\n",
      "[Parallel(n_jobs=-1)]: Done 465 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 815 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1265 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1815 tasks      | elapsed: 19.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2465 tasks      | elapsed: 25.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2880 out of 2880 | elapsed: 31.6min finished\n"
     ]
    }
   ],
   "source": [
    "#data_dmatrix = xgb.DMatrix(data=X_train,label=y_train)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "tuned_parameters = {'alpha': [0.001, 0.01, 0.1], \n",
    "                    'learning_rate': [.01, .3, .5, 1],\n",
    "                   'max_depth': [2, 6,  10],\n",
    "                  'n_estimators': [2, 10, 100, 200],\n",
    "                   'colsample_bytree': [.1, .3, .9, 1],\n",
    "                   'objective': ['reg:linear']}\n",
    "\n",
    "#tuned_parameters = {'alpha': [.01], \n",
    "#                    'learning_rate': [.3],\n",
    "#                   'max_depth': [6],\n",
    "#                    'n_estimators': [100],\n",
    "#                   'colsample_bytree': [.9],\n",
    "#                   'objective': ['reg:linear']}\n",
    "\n",
    "\n",
    "xg_reg = GridSearchCV(xgb.XGBRegressor(), tuned_parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "#xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                #max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "\n",
    "xg_reg.fit(X_train,y_train)\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 490845.120008\n",
      "MAE: 260408.456212\n",
      "MAPE: 1.288777\n",
      "R^2: 0.763546\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def mean_abs_perc_error(y_test, preds):\n",
    "    total = 0\n",
    "    n = len(y_test)\n",
    "    for i in range(0, n-1):\n",
    "        diff = abs(preds[i] - y_test.iloc[i]) / y_test.iloc[i]\n",
    "        total = total + diff\n",
    "    return total / n\n",
    "\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "mape = mean_abs_perc_error(y_test, preds)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "r2 = r2_score(y_test, preds)\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "print(\"MAE: %f\" % (mae))\n",
    "print(\"MAPE: %f\" % (mape))\n",
    "print(\"R^2: %f\" % (r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.001,\n",
       " 'colsample_bytree': 0.9,\n",
       " 'learning_rate': 0.3,\n",
       " 'max_depth': 6,\n",
       " 'n_estimators': 100,\n",
       " 'objective': 'reg:linear'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, as many have argued, XGBoost gives us the best results, a fair amount better than we saw in the other notebooks. Now, let's see our results when we train only on pre-2016 in order to predict 2016 prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_cleaned = drop_geog(clean_data.copy(), ['neighborhood'])\n",
    "one_hot = pd.get_dummies(housing_cleaned['neighborhood'])\n",
    "housing_cleaned = housing_cleaned.drop('neighborhood',axis = 1)\n",
    "\n",
    "housing_cleaned_2016 = housing_cleaned[housing_cleaned['lastsolddateint'] >= 1451606400.0]\n",
    "housing_cleaned_pre2016 = housing_cleaned[housing_cleaned['lastsolddateint'] < 1451606400.0]\n",
    "\n",
    "X_train = housing_cleaned_pre2016.drop('lastsoldprice',axis = 1)\n",
    "y_train = housing_cleaned_pre2016['lastsoldprice']\n",
    "X_test = housing_cleaned_2016.drop('lastsoldprice',axis = 1)\n",
    "y_test = housing_cleaned_2016['lastsoldprice']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train[X_train.columns] = scaler.transform(X_train[X_train.columns])\n",
    "X_train = X_train.join(one_hot)\n",
    "X_test[X_test.columns] = scaler.transform(X_test[X_test.columns])\n",
    "X_test = X_test.join(one_hot)\n",
    "\n",
    "(X_val, X_test, y_val, y_test) = train_test_split(X_test, y_test, test_size=0.5, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=-1)]: Done 215 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 465 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 815 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1265 tasks      | elapsed: 15.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1815 tasks      | elapsed: 24.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2465 tasks      | elapsed: 31.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2880 out of 2880 | elapsed: 40.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 647964.742586\n",
      "MAE: 313178.272478\n",
      "MAPE: 0.246647\n",
      "R^2: 0.597122\n"
     ]
    }
   ],
   "source": [
    "xg_reg = GridSearchCV(xgb.XGBRegressor(), tuned_parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "#xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                #max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "\n",
    "xg_reg.fit(X_train,y_train)\n",
    "preds = xg_reg.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "mape = mean_abs_perc_error(y_test, preds)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "r2 = r2_score(y_test, preds)\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "print(\"MAE: %f\" % (mae))\n",
    "print(\"MAPE: %f\" % (mape))\n",
    "print(\"R^2: %f\" % (r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.001,\n",
       " 'colsample_bytree': 1,\n",
       " 'learning_rate': 0.3,\n",
       " 'max_depth': 6,\n",
       " 'n_estimators': 100,\n",
       " 'objective': 'reg:linear'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, these results are worse than the previous run, but still better than we have seen with many of our other algorithms, equal to our best result (KNN) in the other set of algorithms in the HousePrices notebook.\n",
    "\n",
    "Now, let's look at training only on post-recession prices to predict 2016 prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_cleaned = drop_geog(clean_data.copy(), ['neighborhood'])\n",
    "one_hot = pd.get_dummies(housing_cleaned['neighborhood'])\n",
    "housing_cleaned = housing_cleaned.drop('neighborhood',axis = 1)\n",
    "\n",
    "housing_cleaned_2016 = housing_cleaned[housing_cleaned['lastsolddateint'] >= 1451606400.0]\n",
    "housing_cleaned_pre2016 = housing_cleaned[housing_cleaned['lastsolddateint'] < 1451606400.0]\n",
    "housing_cleaned_2012_2015 = housing_cleaned_pre2016[housing_cleaned_pre2016['lastsolddateint'] >= 1325376000.0]\n",
    "\n",
    "X_train = housing_cleaned_2012_2015.drop('lastsoldprice',axis = 1)\n",
    "y_train = housing_cleaned_2012_2015['lastsoldprice']\n",
    "X_test = housing_cleaned_2016.drop('lastsoldprice',axis = 1)\n",
    "y_test = housing_cleaned_2016['lastsoldprice']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train[X_train.columns] = scaler.transform(X_train[X_train.columns])\n",
    "X_train = X_train.join(one_hot)\n",
    "X_test[X_test.columns] = scaler.transform(X_test[X_test.columns])\n",
    "X_test = X_test.join(one_hot)\n",
    "\n",
    "(X_val, X_test, y_val, y_test) = train_test_split(X_test, y_test, test_size=0.5, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=-1)]: Done 215 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 465 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 815 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1265 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1815 tasks      | elapsed: 23.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2465 tasks      | elapsed: 30.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2880 out of 2880 | elapsed: 39.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 652074.291434\n",
      "MAE: 322219.748081\n",
      "MAPE: 0.247582\n",
      "R^2: 0.591996\n"
     ]
    }
   ],
   "source": [
    "xg_reg = GridSearchCV(xgb.XGBRegressor(), tuned_parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "#xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                #max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "\n",
    "xg_reg.fit(X_train,y_train)\n",
    "preds = xg_reg.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "mape = mean_abs_perc_error(y_test, preds)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "r2 = r2_score(y_test, preds)\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "print(\"MAE: %f\" % (mae))\n",
    "print(\"MAPE: %f\" % (mape))\n",
    "print(\"R^2: %f\" % (r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.001,\n",
       " 'colsample_bytree': 0.9,\n",
       " 'learning_rate': 0.3,\n",
       " 'max_depth': 6,\n",
       " 'n_estimators': 100,\n",
       " 'objective': 'reg:linear'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, though this result is better than most, it is not quite as good (but not substantially worse) than RandomForest and GBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
